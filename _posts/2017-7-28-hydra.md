---
layout: post
title: Hydra - a 4-GPU Workstation for Machine Learning
tags: [GPU, CUDA, Linux, Machine Learning]
---

Hydra is a rack-mountable 4-GPU workstation for Machine Learning research, kindly provided by our partners at [Pacific Research Platform](http://prp.ucsd.edu/).<!-- more -->

* Table of Contents
{:toc}

## Hardware
* Two 8-core [Intel Xeon E5-2620 v4](https://ark.intel.com/products/92986/Intel-Xeon-Processor-E5-2620-v4-20M-Cache-2_10-GHz) processors @ 2.1 GHz
* Four [GeForce GTX 1080 Ti](https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/) Founder's Edition Graphics Cards
* 128GB DDR4 ECC/REG memory (8 x 16GB)
* Two 128GB [SATA DOMs](https://www.supermicro.com/products/nfo/SATADOM.cfm)
* One 3.2TB [Samsung PM1725a HHHL PCIe NVMe SSD](http://www.samsung.com/semiconductor/products/flash-storage/enterprise-ssd/)
* Eight 480GB [Samsung PM863a SATA SSDs](http://www.samsung.com/semiconductor/minisite/ssd/product/enterprise/pm863a.html) (installed in eight hot-swap Drive Bays)
* One [Mellanox ConnectX-4 Lx EN (MCX4131A-BCAT)](http://www.mellanox.com/page/products_dyn?product_family=219&) 40GbE Single Port QSFP28 Network Adapter
* Integrated Intel i350 Dual Port Gigabit Ethernet Controller
* Integrated IPMI 2.0 with Virtual Media over LAN and KVM-over-LAN Support
* Integrated ASPEED AST2400 BMC Graphics
* Supermicro [7048GR-TR](https://www.supermicro.com/products/system/4U/7048/SYS-7048GR-TR.cfm) 4U rack-mountable Tower chassis
* 2000W high efficiency (96%) redundant PSUs, Titanium Level

## Basic Software
1) Performe a minimal installation of CentOS 7 on *pulpo-admin*.

2) Disable Selinux by changing the following line in `/etc/selinux/config`:
```conf
SELINUX=enforcing
```
to:
```conf
SELINUX=disabled
```

3) After copying SSH keys to the host, disable password authentication of SSH by changing the following line in `/etc/ssh/sshd_config`:
```conf
PasswordAuthentication yes
```
to
```conf
PasswordAuthentication no
```

4) Disable GSSAPI authentication of SSH by changing the following line in `/etc/ssh/sshd_config`:
```conf
GSSAPIAuthentication yes
```
to:
```conf
GSSAPIAuthentication no
```

5) Update all packages:
```shell
[root@pulpo-admin ~]# yum -y update
```

6) Reboot;

8) Remove the old kernel:
```shell
[root@pulpo-admin ~]# yum erase -y kernel-3.10.0-514.el7.x86_64
```

9) Install Development Tools
```shell
# yum groupinstall -y "Development Tools"
```

10) Enable EPEL repository:
```shell
# yum install -y epel-release
```

11) Install DKMS, which is required by *CUDA* packages:
```shell
# yum install -y dkms
```

12) Install [Environment Modules](http://modules.sourceforge.net/):
```shell
# yum -y install environment-modules
```

## CUDA
Initially the open source nouveau driver is loaded by default:
```shell
# lsmod | grep nouveau
nouveau              1527946  0
video                  24400  1 nouveau
mxm_wmi                13021  1 nouveau
drm_kms_helper        146456  2 ast,nouveau
ttm                    93908  2 ast,nouveau
i2c_algo_bit           13413  3 ast,igb,nouveau
drm                   372540  5 ast,ttm,drm_kms_helper,nouveau
i2c_core               40756  8 ast,drm,igb,i2c_i801,ipmi_ssif,drm_kms_helper,i2c_algo_bit,nouveau
wmi                    19070  2 mxm_wmi,nouveau
```

Install [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads), using Installer Type `rpm(network)`:
```shell
# yum install -y https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-repo-rhel7-8.0.61-1.x86_64.rpm
# yum clean all
# yum install -y cuda
# reboot
```

Now nouveau is blacklisted with `/etc/modprobe.d/blacklist-nouveau.conf`.
```conf
# RPM Fusion blacklist for nouveau driver - you need to run as root:
# dracut -f /boot/initramfs-$(uname -r).img $(uname -r)
# if nouveau is loaded despite this file.
blacklist nouveau
```

Let's list all Nvidia GPUs:
```shell
# nvidia-smi -L
GPU 0: GeForce GTX 1080 Ti (UUID: GPU-9e5e4bb8-5810-69c5-c783-1759ac6cd0ce)
GPU 1: GeForce GTX 1080 Ti (UUID: GPU-3d046d75-24b5-b06f-5ec2-ba43aeb6b17f)
GPU 2: GeForce GTX 1080 Ti (UUID: GPU-be6407ea-08f6-06d4-732b-47b40896950c)
GPU 3: GeForce GTX 1080 Ti (UUID: GPU-41444e04-2b58-56a6-2a85-318f03017dd6)
```

We note in passing that NVIDIA CUDA Profile Tools Interface is installed at `/usr/local/cuda-8.0/extras/CUPTI`. This ibrary provides advanced profiling support; and is required by current version (1.3) of TensorFlow.

## cuDNN
The current version (1.3) of TensorFlow requires [cuDNN](https://developer.nvidia.com/cudnn) v6.0. Download a tar file for [cuDNN v6.0](https://developer.nvidia.com/rdp/cudnn-download); and unpack it:
```shell
# tar xvfz cudnn-8.0-linux-x64-v5.1.tgz -C /usr/local/
```
which places the header and the libraries in `/usr/local/cuda`, a symbolic link to `/usr/local/cuda-8.0`.

Refresh shared library cache:
```shell
# ldconfig
```
<p class="note"> The CUDA installation has added an entry <strong>cuda-8-0.conf</strong> in <em>/etc/ld.so.conf.d/</em>; so there is no need to alter the <em>LD_LIBRARY_PATH</em> environment variable.</p>
```shell
# cat /etc/ld.so.conf.d/cuda-8-0.conf
/usr/local/cuda-8.0/targets/x86_64-linux/lib
```

## ZFS on SATA SSDs
Install the ZFS repository for RHEL/CentOS 7.3:
```shell
# yum install -y http://download.zfsonlinux.org/epel/zfs-release.el7_3.noarch.rpm
```

We'll install [kABI-tracking kmod ZFS package](https://github.com/zfsonlinux/zfs/wiki/RHEL-%26-CentOS). Follow instructions in the wiki to modify `/etc/yum.repos.d/zfs.repo` then install `zfs`:
```shell
# yum install -y zfs
```
which installs `zfs` as well as its dependencies `kmod-spl`, `kmod-zfs`, `libzfs2`, `libzpool2` & `spl`.

Enable and start ZFS:
```shell
# systemctl preset zfs-import-cache zfs-import-scan zfs-mount zfs.target
# systemctl start zfs.target
```
**NOTE** there is a *preset* file for ZFS at `/usr/lib/systemd/system-preset/50-zfs.preset`:
```conf
# ZFS is enabled by default
enable zfs-import-cache.service
disable zfs-import-scan.service
enable zfs-mount.service
enable zfs-share.service
enable zfs-zed.service
enable zfs.target
```
Here we've only enabled `zfs-import-cache`, `zfs-import-scan` & `zfs-mount zfs.target`. But it's worthwhile looking into [zfs-zed (ZFS Even Daemon)](http://louwrentius.com/the-zfs-event-daemon-on-linux.html).

Find out the disk IDs of the eight 480GB Samsung PM863a SATA SSDs:
```shell
# ls -lh /dev/disk/by-id/
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411211 -> ../../sde
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411217 -> ../../sdf
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411300 -> ../../sdh
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411303 -> ../../sdb
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411318 -> ../../sdc
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411319 -> ../../sdd
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411320 -> ../../sda
lrwxrwxrwx 1 root root  9 Jul 28 21:05 ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411321 -> ../../sdg
```

Use a shell script `mkzfs` to create a ZFS on the eight 480GB Samsung PM863a SATA SSDs:
```shell
#!/bin/bash
/sbin/modprobe zfs

zpool create -f -m /home home -o ashift=12 raidz1 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411320 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411303 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411318 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411319

zpool add -f home -o ashift=12 raidz1 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411211 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411217 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411321 \
      ata-SAMSUNG_MZ7LM480HMHQ-00005_S2UJNX0J411300

zfs set recordsize=1024K home
zfs set checksum=fletcher4 home
zfs set atime=off home
```
This script will automatically create `/etc/zfs/zpool.cache`; so we don't need to run the following command as instructed in the [Arch Linux wiki article]((https://wiki.archlinux.org/index.php/ZFS)):
```shell
zpool set cachefile=/etc/zfs/zpool.cache <pool>
```

## XFS on NVMe SSD
Partition the NVMe SSD:
```shell
# parted /dev/nvme0n1
GNU Parted 3.1
Using /dev/nvme0n1
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) mklabel gpt
Warning: The existing disk label on /dev/nvme0n1 will be destroyed and all data on this
disk will be lost. Do you want to continue?
Yes/No? Yes
(parted) unit s
(parted) print free
Model: Unknown (unknown)
Disk /dev/nvme0n1: 6251233968s
Sector size (logical/physical): 512B/512B
Partition Table: gpt
Disk Flags:

Number  Start  End          Size         File system  Name  Flags
        34s    6251233934s  6251233901s  Free Space

(parted) mkpart primary 0% 100%
(parted) print free
Model: Unknown (unknown)
Disk /dev/nvme0n1: 6251233968s
Sector size (logical/physical): 512B/512B
Partition Table: gpt
Disk Flags:

Number  Start        End          Size         File system  Name     Flags
        34s          2047s        2014s        Free Space
 1      2048s        6251233279s  6251231232s               primary
        6251233280s  6251233934s  655s         Free Space

(parted) quit
Information: You may need to update /etc/fstab.
```
Create XFS on the NVMe partition:
```shell
# mkfs.xfs /dev/nvme0n1p1
meta-data=/dev/nvme0n1p1         isize=512    agcount=4, agsize=195350976 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0, sparse=0
data     =                       bsize=4096   blocks=781403904, imaxpct=5
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=381544, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
# xfs_admin -L scratch /dev/nvme0n1p1
writing all SBs
new label = "scratch"
# mkdir /scratch
# mount /dev/nvme0n1p1 /scratch
# chmod 1777 /scratch

# ls -ld /scratch
drwxrwxrwt 2 root root 6 Jul 28 21:38 /scratch
```
<p class="note">We have the sticky bit set.</p>

Find out the UUID of the NVMe partition:
```shell
# cd /dev/disk/by-uuid/
# ls -l
lrwxrwxrwx 1 root root 15 Jul 28 21:39 f67abe6c-42db-4006-aece-ea87b89b8eaf -> ../../nvme0n1p1
```
Append the following line to `/etc/fstab` so that the partition will be automatically mounted on startup:
```conf
UUID=f67abe6c-42db-4006-aece-ea87b89b8eaf /scratch                xfs     defaults        0 0
```

## Anaconda Python
1) Download [Anaconda3 4.4.0 for Linux Installer](https://www.continuum.io/downloads#linux) and install it:
```shell
# curl -O https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86_64.sh
# chmod +x Anaconda3-4.4.0-Linux-x86_64.sh
# ./Anaconda3-4.4.0-Linux-x86_64.sh
```
which installs Python 3.6 at `/opt/anaconda3`.

2) Download [Anaconda2 4.4.0 for Linux Installer](https://www.continuum.io/downloads#linux) and install it:
```shell
# curl -O https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh
# chmod +x Anaconda2-4.4.0-Linux-x86_64.sh
# ./Anaconda2-4.4.0-Linux-x86_64.sh
```
which installs Python 2.7 at `/opt/anaconda2`.

## TensorFlow with Anaconda Python 3.6
Append `/opt/anaconda3/bin` to PATH:
```shell
export PATH=/opt/anaconda3/bin:$PATH
```

First update Anaconda Python 3.6:
```shell
# conda update conda
# conda update anaconda
# conda update python
# conda update --all
```

Then install TensorFlow with GPU support:
```shell
# pip install --upgrade tensorflow-gpu
```
